{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_raw = pd.read_csv(\"baf.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_split = df_raw.iloc[:, 0].str.split(';', expand=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = [\"age\", \"job\", \"marital\", \"education\", \"default\", \"housing\", \"loan\", \n",
    "           \"contact\", \"month\", \"day_of_week\", \"duration\", \"campaign\", \"pdays\", \n",
    "           \"previous\", \"poutcome\", \"emp.var.rate\", \"cons.price.idx\", \n",
    "           \"cons.conf.idx\", \"euribor3m\", \"nr.employed\", \"y\"]\n",
    "df_split.columns = columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_split.columns = df_split.columns.str.replace('\"', '')\n",
    "df_split = df_split.applymap(lambda x: x.replace('\"', '') if isinstance(x, str) else x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column names in DataFrame: Index(['age', 'job', 'marital', 'education', 'default', 'housing', 'loan',\n",
      "       'contact', 'month', 'day_of_week', 'duration', 'campaign', 'pdays',\n",
      "       'previous', 'poutcome', 'emp.var.rate', 'cons.price.idx',\n",
      "       'cons.conf.idx', 'euribor3m', 'nr.employed', 'y'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(\"Column names in DataFrame:\", df_split.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_column = 'day_of_week'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "if target_column in df_split.columns:\n",
    "    y = df_split[target_column]\n",
    "    X = df_split.drop(target_column, axis=1)\n",
    "else:\n",
    "    print(f\"Column '{target_column}' not found in the DataFrame. Available columns are: {df_split.columns}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pd.get_dummies(X, drop_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First few rows of feature set (X):\n",
      "   age_18  age_19  age_20  age_21  age_22  age_23  age_24  age_25  age_26  \\\n",
      "0   False   False   False   False   False   False   False   False   False   \n",
      "1   False   False   False   False   False   False   False   False   False   \n",
      "2   False   False   False   False   False   False   False   False   False   \n",
      "3   False   False   False   False   False   False   False   False   False   \n",
      "4   False   False   False   False   False   False   False   False   False   \n",
      "\n",
      "   age_27  ...  nr.employed_5008.7  nr.employed_5017.5  nr.employed_5023.5  \\\n",
      "0   False  ...               False               False               False   \n",
      "1   False  ...               False               False               False   \n",
      "2   False  ...               False               False               False   \n",
      "3   False  ...               False               False               False   \n",
      "4   False  ...               False               False               False   \n",
      "\n",
      "   nr.employed_5076.2  nr.employed_5099.1  nr.employed_5176.3  \\\n",
      "0               False               False               False   \n",
      "1               False               False               False   \n",
      "2               False               False               False   \n",
      "3               False               False               False   \n",
      "4               False               False               False   \n",
      "\n",
      "   nr.employed_5191  nr.employed_5195.8  nr.employed_5228.1  y_yes  \n",
      "0              True               False               False  False  \n",
      "1              True               False               False  False  \n",
      "2              True               False               False  False  \n",
      "3              True               False               False  False  \n",
      "4              True               False               False  False  \n",
      "\n",
      "[5 rows x 2118 columns]\n",
      "First few rows of target (y):\n",
      "0    mon\n",
      "1    mon\n",
      "2    mon\n",
      "3    mon\n",
      "4    mon\n",
      "Name: day_of_week, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(\"First few rows of feature set (X):\")\n",
    "print(X.head())\n",
    "print(\"First few rows of target (y):\")\n",
    "print(y.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler= StandardScaler()\n",
    "X_train=scaler.fit_transform(X_train)\n",
    "X_test=scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\parvj\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "log_model = LogisticRegression()\n",
    "log_model.fit(X_train, y_train)\n",
    "log_pred = log_model.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree_model = DecisionTreeClassifier()\n",
    "tree_model.fit(X_train, y_train)\n",
    "tree_pred = tree_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "forest_model = RandomForestClassifier()\n",
    "forest_model.fit(X_train, y_train)\n",
    "forest_pred = forest_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         fri       0.68      0.67      0.67      2313\n",
      "         mon       0.69      0.73      0.71      2602\n",
      "         thu       0.76      0.76      0.76      2603\n",
      "         tue       0.70      0.70      0.70      2436\n",
      "         wed       0.64      0.60      0.62      2403\n",
      "\n",
      "    accuracy                           0.69     12357\n",
      "   macro avg       0.69      0.69      0.69     12357\n",
      "weighted avg       0.69      0.69      0.69     12357\n",
      "\n",
      "Decision Tree:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         fri       0.73      0.72      0.73      2313\n",
      "         mon       0.74      0.75      0.74      2602\n",
      "         thu       0.83      0.82      0.83      2603\n",
      "         tue       0.71      0.73      0.72      2436\n",
      "         wed       0.70      0.69      0.70      2403\n",
      "\n",
      "    accuracy                           0.75     12357\n",
      "   macro avg       0.74      0.74      0.74     12357\n",
      "weighted avg       0.75      0.75      0.75     12357\n",
      "\n",
      "Random Forest:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         fri       0.78      0.75      0.76      2313\n",
      "         mon       0.72      0.81      0.76      2602\n",
      "         thu       0.86      0.83      0.85      2603\n",
      "         tue       0.74      0.75      0.75      2436\n",
      "         wed       0.75      0.70      0.72      2403\n",
      "\n",
      "    accuracy                           0.77     12357\n",
      "   macro avg       0.77      0.77      0.77     12357\n",
      "weighted avg       0.77      0.77      0.77     12357\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Logistic Regression:\\n\", classification_report(y_test, log_pred))\n",
    "print(\"Decision Tree:\\n\", classification_report(y_test, tree_pred))\n",
    "print(\"Random Forest:\\n\", classification_report(y_test, forest_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\parvj\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:425: FitFailedWarning: \n",
      "90 fits failed out of a total of 270.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "62 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\parvj\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 732, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\parvj\\anaconda3\\Lib\\site-packages\\sklearn\\base.py\", line 1144, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"c:\\Users\\parvj\\anaconda3\\Lib\\site-packages\\sklearn\\base.py\", line 637, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"c:\\Users\\parvj\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 95, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'max_features' parameter of RandomForestClassifier must be an int in the range [1, inf), a float in the range (0.0, 1.0], a str among {'sqrt', 'log2'} or None. Got 'auto' instead.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "28 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\parvj\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 732, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\parvj\\anaconda3\\Lib\\site-packages\\sklearn\\base.py\", line 1144, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"c:\\Users\\parvj\\anaconda3\\Lib\\site-packages\\sklearn\\base.py\", line 637, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"c:\\Users\\parvj\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 95, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'max_features' parameter of RandomForestClassifier must be an int in the range [1, inf), a float in the range (0.0, 1.0], a str among {'log2', 'sqrt'} or None. Got 'auto' instead.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "c:\\Users\\parvj\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:976: UserWarning: One or more of the test scores are non-finite: [       nan        nan        nan 0.61694055 0.6267898  0.63282543\n",
      " 0.5095897  0.52041332 0.52197278        nan        nan        nan\n",
      " 0.65037596 0.66071187 0.65984477 0.57292478 0.59515773 0.60788781\n",
      "        nan        nan        nan 0.67215833 0.67652862 0.67656317\n",
      " 0.60788651 0.65540548 0.65131207        nan        nan        nan\n",
      " 0.62592338 0.62973869 0.62689433 0.50147368 0.52713978 0.53862038\n",
      "        nan        nan        nan 0.65485023 0.66237668 0.6618569\n",
      " 0.57278585 0.59890335 0.61347191        nan        nan        nan\n",
      " 0.66851614 0.67378784 0.68266774 0.62946198 0.64791387 0.65370586]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'criterion': 'entropy', 'max_depth': 8, 'max_features': 'sqrt', 'n_estimators': 300}\n"
     ]
    }
   ],
   "source": [
    "param_grid = {\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'max_features': ['auto', 'sqrt', 'log2'],\n",
    "    'max_depth': [4, 6, 8],\n",
    "    'criterion': ['gini', 'entropy']\n",
    "}\n",
    "grid_search = GridSearchCV(estimator=forest_model, param_grid=param_grid, cv=5, n_jobs=-1)\n",
    "grid_search.fit(X_train, y_train)\n",
    "best_params = grid_search.best_params_\n",
    "\n",
    "print(\"Best Parameters:\", best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimized_forest_model = RandomForestClassifier(**best_params)\n",
    "optimized_forest_model.fit(X_train, y_train)\n",
    "optimized_forest_pred = optimized_forest_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimized Random Forest:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         fri       0.86      0.56      0.68      2313\n",
      "         mon       0.67      0.77      0.72      2602\n",
      "         thu       0.59      0.86      0.70      2603\n",
      "         tue       0.76      0.64      0.69      2436\n",
      "         wed       0.74      0.61      0.67      2403\n",
      "\n",
      "    accuracy                           0.69     12357\n",
      "   macro avg       0.72      0.69      0.69     12357\n",
      "weighted avg       0.72      0.69      0.69     12357\n",
      "\n",
      "Confusion Matrix:\n",
      " [[1288  320  360   86  259]\n",
      " [   1 2015  312  143  131]\n",
      " [ 122   39 2239   78  125]\n",
      " [   4  367  504 1548   13]\n",
      " [  88  262  405  183 1465]]\n",
      "Accuracy Score:\n",
      " 0.6923201424293922\n"
     ]
    }
   ],
   "source": [
    "print(\"Optimized Random Forest:\\n\", classification_report(y_test, optimized_forest_pred))\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, optimized_forest_pred))\n",
    "print(\"Accuracy Score:\\n\", accuracy_score(y_test, optimized_forest_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
